const data = [{
    title:'Data Augmentation is a Hyperparameter: Cherry-picked Self-Supervision for Unsupervised Anomaly Detection is Creating the Illusion of Success',
    sub_title:'Guillermo Ortiz-Jimenez, Pau de Jorge, Amartya Sanyal, Adel Bibi, Puneet K. Dokania, Pascal Frossard, Grégory Rogez, Philip Torr',
    pub:'23 Jul 2023',
    last_mod:'23 Jul 2023',
    card:{
        expert_review:'Guillermo Ortiz-Jimenez',
        auth:'Self-supervised learning (SSL) has emerged as a promising alternative to create supervisory signals to real-world problems, avoiding the extensive cost of manual labeling. SSL is particularly attractive for unsupervised tasks such as anomaly detection (AD), where labeled anomalies are rare or often nonexistent. A large catalog of augmentation functions has been used for SSL-based AD (SSAD) on image data, and recent works have reported that the type of augmentation has a significant impact on accuracy. Motivated by those, this work sets out to put image-based SSAD under a larger lens and investigate the role of data augmentation in SSAD. Through extensive experiments on 3 different detector models and across 420 AD tasks, we provide comprehensive numerical and visual evidences that the alignment between data augmentation and anomaly-generating mechanism is the key to the success of SSAD, and in the lack thereof, SSL may even impair accuracy. To the best of our knowledge, this is the first meta-analysis on the role of data augmentation in SSAD.',
        certification:'Expert Certification',
        license:'Creative Commons Attribution 4.0 International (CC BY 4.0)',
        len:'Regular submission (no more than 12 pages of main content)',
        last_submission:'',
        code:'https://github.com/gortizji/co_features',
        editor:'Jakub Mikolaj Tomczak'
    }
},
{
    title:'Self-Supervision is All You Need for Solving Rubik’s Cube',
    sub_title:'Kyo Takano',
    pub:'25 Jul 2023',
    last_mod:'25 Jul 2023',
    card:{
        expert_review:'Guillermo Ortiz-Jimenez',
        auth:"Existing combinatorial search methods are often complex and require some level of expertise. This work introduces a simple and efficient deep learning method for solving combinatorial problems with a predefined goal, represented by Rubik's Cube. We demonstrate that, for such problems, training a deep neural network on random scrambles branching from the goal state is sufficient to achieve near-optimal solutions. When tested on Rubik's Cube, 15 Puzzle, and 7 7 Lights Out, our method outperformed the previous state-of-the-art method DeepCubeA, improving the trade-off between solution optimality and computational cost, despite significantly less training data. Furthermore, we investigate the scaling law of our Rubik's Cube solver with respect to model size and training data volume.",
        certification:'Expert Certification',
        license:'Creative Commons Attribution 4.0 International (CC BY 4.0)',
        len:'Regular submission (no more than 12 pages of main content)',
        last_submission:'',
        code:'https://github.com/kyo-takano/efficientcube',
        editor:'Marc Lanctot'
    }
}
]